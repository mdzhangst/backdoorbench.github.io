<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>attack.blind &mdash; BackdoorBench v2 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/mytheme.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/favicon.png"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/js/version_alert.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/pyg_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../start/installation.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../start/quickstart.html">Quick Start by Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/bddataset.html">Build Your Own Backdoor Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/attack.html">Build Your Own Backdoor Attack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/defense.html">Build Your Own Backdoor Defense</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PACKAGE REFERENCE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules/attack.html">packages of attack and defense</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Visualization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../visualization/analysis_readme.html">Analysis Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../visualization/Demo_FV.html">Demo_FV</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">BackdoorBench</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">attack.blind</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for attack.blind</h1><div class="highlight"><pre>
<span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">this script is for blind attack</span>
<span class="sd">from https://github.com/ebagdasa/backdoors101</span>

<span class="sd">@inproceedings {bagdasaryan2020blind,</span>
<span class="sd"> author = {Eugene Bagdasaryan and Vitaly Shmatikov},</span>
<span class="sd"> title = {Blind Backdoors in Deep Learning Models},</span>
<span class="sd"> booktitle = {30th {USENIX} Security Symposium ({USENIX} Security 21)},</span>
<span class="sd"> year = {2021},</span>
<span class="sd"> isbn = {978-1-939133-24-3},</span>
<span class="sd"> pages = {1505--1521},</span>
<span class="sd"> url = {https://www.usenix.org/conference/usenixsecurity21/presentation/bagdasaryan},</span>
<span class="sd"> publisher = {{USENIX} Association},</span>
<span class="sd"> month = aug,</span>
<span class="sd">}</span>

<span class="sd">Original code file license is as the end of this script</span>

<span class="sd">Note that for fairness issue, we apply the same total training epochs as all other attack methods. But for Blind, it may not be the best choice.</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="c1"># os.chdir(sys.path[0])</span>
<span class="c1"># sys.path.append(&#39;../&#39;)</span>
<span class="c1"># os.getcwd()</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copyfile</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">asdict</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Module</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">functional</span>

<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">torch.utils.data.dataloader</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="kn">from</span> <span class="nn">.badnet</span> <span class="kn">import</span> <span class="n">BadNet</span>
<span class="kn">from</span> <span class="nn">backdoorbench.utils.backdoor_generate_poison_index</span> <span class="kn">import</span> <span class="n">generate_poison_index_from_label_transform</span>
<span class="kn">from</span> <span class="nn">backdoorbench.utils.aggregate_block.bd_attack_generate</span> <span class="kn">import</span> <span class="n">bd_attack_label_trans_generate</span>
<span class="kn">from</span> <span class="nn">backdoorbench.utils.aggregate_block.model_trainer_generate</span> <span class="kn">import</span> <span class="n">generate_cls_model</span>
<span class="kn">from</span> <span class="nn">backdoorbench.utils.aggregate_block.train_settings_generate</span> <span class="kn">import</span> <span class="n">argparser_opt_scheduler</span><span class="p">,</span> <span class="n">argparser_criterion</span>
<span class="kn">from</span> <span class="nn">backdoorbench.utils.save_load_attack</span> <span class="kn">import</span> <span class="n">save_attack_result</span>
<span class="kn">from</span> <span class="nn">backdoorbench.utils.trainer_cls</span> <span class="kn">import</span> <span class="n">all_acc</span><span class="p">,</span> <span class="n">given_dataloader_test</span><span class="p">,</span> <span class="n">plot_loss</span><span class="p">,</span> <span class="n">plot_acc_like_metric</span><span class="p">,</span> <span class="n">Metric_Aggregator</span><span class="p">,</span> <span class="n">test_given_dataloader_on_mix</span>
<span class="kn">from</span> <span class="nn">backdoorbench.utils.bd_dataset_v2</span> <span class="kn">import</span> <span class="n">prepro_cls_DatasetBD_v2</span><span class="p">,</span> <span class="n">dataset_wrapper_with_transform</span>
<span class="kn">from</span> <span class="nn">backdoorbench.utils.aggregate_block.bd_attack_generate</span> <span class="kn">import</span> <span class="n">general_compose</span>
<span class="kn">from</span> <span class="nn">backdoorbench.utils.aggregate_block.dataset_and_transform_generate</span> <span class="kn">import</span> <span class="n">dataset_and_transform_generate</span>

<span class="n">transform_to_image</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">()</span>
<span class="n">transform_to_tensor</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>

<span class="n">ALL_TASKS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;backdoor&#39;</span><span class="p">,</span> <span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="s1">&#39;sentinet_evasion&#39;</span><span class="p">,</span>  <span class="c1"># &#39;spectral_evasion&#39;,</span>
             <span class="s1">&#39;neural_cleanse&#39;</span><span class="p">,</span> <span class="s1">&#39;mask_norm&#39;</span><span class="p">,</span> <span class="s1">&#39;sums&#39;</span><span class="p">,</span> <span class="s1">&#39;neural_cleanse_part1&#39;</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">Params</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># Corresponds to the class module: tasks.mnist_task.MNISTTask</span>
        <span class="c1"># See other tasks in the task folder.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;MNIST&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_time</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">commit</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_seedOptional</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># training params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_interval</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span>
        <span class="c1"># model arch is usually defined by the task</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resume_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decay</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler_milestonesOptional</span><span class="p">:</span> <span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;.data/&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform_train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="s2">&quot;Do not apply transformations to the training images.&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_batch_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="s2">&quot;For large datasets stop training earlier.&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="s2">&quot;No need to set, updated by the Task class.&quot;</span>

        <span class="c1"># gradient shaping/DP params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dp</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dp_clip</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dp_sigma</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># attack params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backdoor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backdoor_label</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">poisoning_proportion</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># backdoors proportion in backdoor loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">synthesizer</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;pattern&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backdoor_dynamic_position</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># losses to balance: `normal`, `backdoor`, `neural_cleanse`, `sentinet`,</span>
        <span class="c1"># `backdoor_multi`.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_tasks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_balance</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;MGDA&#39;</span>
        <span class="s2">&quot;loss_balancing: `fixed` or `MGDA`&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># approaches to balance losses with MGDA: `none`, `loss`,</span>
        <span class="c1"># `loss+`, `l2`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mgda_normalize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fixed_scales</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># relabel images with poison_number</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">poison_images</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">poison_images_test</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># optimizations:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alternating_attack</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># Disable BatchNorm and Dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">switch_to_eval</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># nc evasion</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nc_p_norm</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="c1"># spectral evasion</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spectral_similarity</span><span class="p">:</span> <span class="s1">&#39;str&#39;</span> <span class="o">=</span> <span class="s1">&#39;norm&#39;</span>

        <span class="c1"># logging</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">report_train_loss</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_on_epochs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_scale_values</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">print_memory_consumption</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_timing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">timing_data</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Temporary storage for running values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">running_losses</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">running_scales</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># FL params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fl</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fl_no_models</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fl_local_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fl_total_participants</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">80000</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fl_eta</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fl_sample_dirichlet</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fl_dirichlet_alpha</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fl_diff_privacy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fl_dp_clip</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fl_dp_noise</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># FL attack details. Set no adversaries to perform the attack:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fl_number_of_adversaries</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fl_single_epoch_attack</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fl_weight_scale</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># enable logging anyways when saving statistics</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_timing</span> <span class="ow">or</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">print_memory_consumption</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">folder_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;saved_models/model_&#39;</span> \
                               <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">current_time</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">running_losses</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">running_scales</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">timing_data</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_tasks</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">t</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ALL_TASKS</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Task </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s1"> is not part of the supported &#39;</span>
                                 <span class="sa">f</span><span class="s1">&#39;tasks: </span><span class="si">{</span><span class="n">ALL_TASKS</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">asdict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Metric</span><span class="p">:</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">plottable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">running_metric</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">main_metric_name</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">train</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">running_metric</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_value</span><span class="p">()</span>
        <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">val</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">: &#39;</span> <span class="o">+</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="bp">NotImplemented</span>

    <span class="k">def</span> <span class="nf">accumulate_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">current_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_metric</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">current_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">running_metric</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_value</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">running_metric</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">metrics</span>

    <span class="k">def</span> <span class="nf">get_main_metric_value</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">main_metric_name</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;For metric </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1"> define &#39;</span>
                             <span class="sa">f</span><span class="s1">&#39;attribute main_metric_name.&#39;</span><span class="p">)</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_value</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">metrics</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">main_metric_name</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">reset_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">running_metric</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tb_writer</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">tb_prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">tb_writer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">plottable</span><span class="p">:</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_value</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">tb_prefix</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                                     <span class="n">scalar_value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span>
                                     <span class="n">global_step</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>
            <span class="n">tb_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>


<span class="k">class</span> <span class="nc">AccuracyMetric</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">top_k</span> <span class="o">=</span> <span class="n">top_k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">main_metric_name</span> <span class="o">=</span> <span class="s1">&#39;Top-1&#39;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                       <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes the precision@k for the specified values of k&quot;&quot;&quot;</span>
        <span class="n">max_k</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">top_k</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">max_k</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>

        <span class="n">res</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">top_k</span><span class="p">:</span>
            <span class="n">correct_k</span> <span class="o">=</span> <span class="n">correct</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">res</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;Top-</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">correct_k</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="mf">100.0</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">res</span>


<span class="k">class</span> <span class="nc">TestLossMetric</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">criterion</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">main_metric_name</span> <span class="o">=</span> <span class="s1">&#39;value&#39;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                       <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes the precision@k for the specified values of k&quot;&quot;&quot;</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()}</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">Batch</span><span class="p">:</span>
    <span class="n">batch_id</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>

    <span class="c1"># For PIPA experiment we use this field to store identity label.</span>
    <span class="n">aux</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">aux</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">aux</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">Batch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_id</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">aux</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">aux</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">aux</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">Batch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_id</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">aux</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">clip</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">aux</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">aux</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">Batch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_id</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">aux</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Task</span><span class="p">:</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">Params</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">train_dataset</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">test_dataset</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">model</span><span class="p">:</span> <span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">criterion</span><span class="p">:</span> <span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Metric</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                                     <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="s2">&quot;Generic normalization for input data.&quot;</span>
    <span class="n">input_shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Params</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_task</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">init_task</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resume_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">argparser_opt_scheduler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_criterion</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="n">AccuracyMetric</span><span class="p">(),</span> <span class="n">TestLossMetric</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_input_shape</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="bp">NotImplemented</span>

    <span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Module</span><span class="p">:</span>
        <span class="k">raise</span> <span class="bp">NotImplemented</span>

    <span class="k">def</span> <span class="nf">make_criterion</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Module</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize with Cross Entropy by default.</span>

<span class="sd">        We use reduction `none` to support gradient shaping defense.</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">resume_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">resume_model</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Resuming training from- </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">resume_model</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="n">loaded_params</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;saved_models/&quot;</span>
                                       <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">resume_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                                       <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">loaded_params</span><span class="p">[</span><span class="s1">&#39;state_dict&#39;</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">start_epoch</span> <span class="o">=</span> <span class="n">loaded_params</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">loaded_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>

            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded parameters from- saved model: LR is&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">lr</span><span class="si">}</span><span class="s2"> and current epoch is&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">start_epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_input_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Batch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Process data into a batch.</span>

<span class="sd">        Specific for different datasets and data loaders this method unifies</span>
<span class="sd">        the output by returning the object of class Batch.</span>
<span class="sd">        :param batch_id: id of the batch</span>
<span class="sd">        :param data: object returned by the Loader.</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">Batch</span><span class="p">(</span><span class="n">batch_id</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">accumulate_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">:</span>
            <span class="n">metric</span><span class="o">.</span><span class="n">accumulate_on_batch</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reset_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">:</span>
            <span class="n">metric</span><span class="o">.</span><span class="n">reset_metric</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">report_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span>
                       <span class="n">tb_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tb_prefix</span><span class="o">=</span><span class="s1">&#39;Metric/&#39;</span><span class="p">):</span>
        <span class="n">metric_text</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">:</span>
            <span class="n">metric_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">metric</span><span class="p">))</span>
            <span class="n">metric</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tb_writer</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">tb_prefix</span><span class="o">=</span><span class="n">tb_prefix</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="n">step</span><span class="si">:</span><span class="s1">4d</span><span class="si">}</span><span class="s1">. </span><span class="si">{</span><span class="s2">&quot; | &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">metric_text</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_main_metric_value</span><span class="p">()</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">get_batch_accuracy</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes the precision@k for the specified values of k&quot;&quot;&quot;</span>
        <span class="n">max_k</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">top_k</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">max_k</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>

        <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">top_k</span><span class="p">:</span>
            <span class="n">correct_k</span> <span class="o">=</span> <span class="n">correct</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">correct_k</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="mf">100.0</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">res</span>


<span class="k">class</span> <span class="nc">Synthesizer</span><span class="p">:</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">Params</span>
    <span class="n">task</span><span class="p">:</span> <span class="n">Task</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task</span><span class="p">:</span> <span class="n">Task</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">=</span> <span class="n">task</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">task</span><span class="o">.</span><span class="n">params</span>

    <span class="k">def</span> <span class="nf">make_backdoor_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Batch</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">attack</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Batch</span><span class="p">:</span>

        <span class="c1"># Don&#39;t attack if only normal loss task.</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">attack</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">loss_tasks</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;normal&#39;</span><span class="p">]</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">test</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">batch</span>

        <span class="k">if</span> <span class="n">test</span><span class="p">:</span>
            <span class="n">attack_portion</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">attack_portion</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span>
                <span class="n">batch</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">poisoning_proportion</span><span class="p">)</span>

        <span class="n">backdoored_batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply_backdoor</span><span class="p">(</span><span class="n">backdoored_batch</span><span class="p">,</span> <span class="n">attack_portion</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">backdoored_batch</span>

    <span class="k">def</span> <span class="nf">apply_backdoor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">attack_portion</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Modifies only a portion of the batch (represents batch poisoning).</span>

<span class="sd">        :param batch:</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">synthesize_inputs</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">attack_portion</span><span class="o">=</span><span class="n">attack_portion</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">synthesize_labels</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">attack_portion</span><span class="o">=</span><span class="n">attack_portion</span><span class="p">)</span>

        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">synthesize_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">attack_portion</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="bp">NotImplemented</span>

    <span class="k">def</span> <span class="nf">synthesize_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">attack_portion</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="bp">NotImplemented</span>


<span class="k">def</span> <span class="nf">record_time</span><span class="p">(</span><span class="n">params</span><span class="p">:</span> <span class="n">Params</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">t</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">and</span> <span class="n">params</span><span class="o">.</span><span class="n">save_timing</span> <span class="o">==</span> <span class="n">name</span> <span class="ow">or</span> <span class="n">params</span><span class="o">.</span><span class="n">save_timing</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
        <span class="n">params</span><span class="o">.</span><span class="n">timing_data</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="mi">1000</span> <span class="o">*</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">t</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">compute_normal_loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span>
                        <span class="n">labels</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">record_time</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="s1">&#39;forward&#39;</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="o">.</span><span class="n">dp</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">grads</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                                         <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span>
                                          <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">],</span>
                                         <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="n">record_time</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="s1">&#39;backward&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span>


<span class="k">def</span> <span class="nf">get_grads</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                                     <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span>
                                      <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">],</span>
                                     <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">record_time</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="s1">&#39;backward&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">grads</span>


<span class="k">def</span> <span class="nf">th</span><span class="p">(</span><span class="n">vector</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">+</span> <span class="mf">0.5</span>


<span class="k">def</span> <span class="nf">norm_loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">grads</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">nc_p_norm</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">th</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">mask</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">params</span><span class="o">.</span><span class="n">nc_p_norm</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">th</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">mask</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Not support mask norm.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">grads</span><span class="p">:</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">get_grads</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">norm</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">norm</span><span class="p">,</span> <span class="n">grads</span>


<span class="k">def</span> <span class="nf">compute_backdoor_loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">inputs_back</span><span class="p">,</span>
                          <span class="n">labels_back</span><span class="p">,</span> <span class="n">grads</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs_back</span><span class="p">)</span>
    <span class="n">record_time</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="s1">&#39;forward&#39;</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels_back</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">task</span> <span class="o">==</span> <span class="s1">&#39;Pipa&#39;</span><span class="p">:</span>
        <span class="n">loss</span><span class="p">[</span><span class="n">labels_back</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*=</span> <span class="mf">0.001</span>
        <span class="k">if</span> <span class="n">labels_back</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">loss</span><span class="p">[:]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="o">.</span><span class="n">dp</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">grads</span><span class="p">:</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">get_grads</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span>


<span class="k">def</span> <span class="nf">compute_all_losses_and_grads</span><span class="p">(</span><span class="n">loss_tasks</span><span class="p">,</span> <span class="n">attack</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span>
                                 <span class="n">batch</span><span class="p">,</span> <span class="n">batch_back</span><span class="p">,</span>
                                 <span class="n">compute_grad</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">loss_values</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">loss_tasks</span><span class="p">:</span>
        <span class="c1"># if compute_grad:</span>
        <span class="c1">#     model.zero_grad()</span>
        <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="s1">&#39;normal&#39;</span><span class="p">:</span>
            <span class="n">loss_values</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">grads</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_normal_loss</span><span class="p">(</span><span class="n">attack</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
                                                           <span class="n">model</span><span class="p">,</span>
                                                           <span class="n">criterion</span><span class="p">,</span>
                                                           <span class="n">batch</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span>
                                                           <span class="n">batch</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>
                                                           <span class="n">grads</span><span class="o">=</span><span class="n">compute_grad</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">t</span> <span class="o">==</span> <span class="s1">&#39;backdoor&#39;</span><span class="p">:</span>
            <span class="n">loss_values</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">grads</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_backdoor_loss</span><span class="p">(</span><span class="n">attack</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
                                                             <span class="n">model</span><span class="p">,</span>
                                                             <span class="n">criterion</span><span class="p">,</span>
                                                             <span class="n">batch_back</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span>
                                                             <span class="n">batch_back</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>
                                                             <span class="n">grads</span><span class="o">=</span><span class="n">compute_grad</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">t</span> <span class="o">==</span> <span class="s1">&#39;mask_norm&#39;</span><span class="p">:</span>
            <span class="n">loss_values</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">grads</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">norm_loss</span><span class="p">(</span><span class="n">attack</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">attack</span><span class="o">.</span><span class="n">nc_model</span><span class="p">,</span>
                                                 <span class="n">grads</span><span class="o">=</span><span class="n">compute_grad</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">t</span> <span class="o">==</span> <span class="s1">&#39;neural_cleanse_part1&#39;</span><span class="p">:</span>
            <span class="n">loss_values</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">grads</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_normal_loss</span><span class="p">(</span><span class="n">attack</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
                                                           <span class="n">model</span><span class="p">,</span>
                                                           <span class="n">criterion</span><span class="p">,</span>
                                                           <span class="n">batch</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span>
                                                           <span class="n">batch_back</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>
                                                           <span class="n">grads</span><span class="o">=</span><span class="n">compute_grad</span><span class="p">,</span>
                                                           <span class="p">)</span>

    <span class="k">return</span> <span class="n">loss_values</span><span class="p">,</span> <span class="n">grads</span>


<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for models with added support for GradCam activation map</span>
<span class="sd">    and a SentiNet defense. The GradCam design is taken from:</span>
<span class="sd">https://medium.com/@stepanulyanin/implementing-grad-cam-in-pytorch-ea0937c31e82</span>
<span class="sd">    If you are not planning to utilize SentiNet defense just import any model</span>
<span class="sd">    you like for your tasks.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">activations_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grad</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient</span> <span class="o">=</span> <span class="n">grad</span>

    <span class="k">def</span> <span class="nf">get_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient</span>

    <span class="k">def</span> <span class="nf">get_activations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">switch_grads</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="n">n</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="n">enable</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get latent representation, eg logit layer.</span>
<span class="sd">        :param x:</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="bp">NotImplemented</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">latent</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">raise</span> <span class="bp">NotImplemented</span>


<span class="k">class</span> <span class="nc">Attack</span><span class="p">:</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">Params</span>
    <span class="n">synthesizer</span><span class="p">:</span> <span class="n">Synthesizer</span>
    <span class="n">nc_model</span><span class="p">:</span> <span class="n">Model</span>
    <span class="n">nc_optim</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span>
    <span class="n">loss_hist</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

    <span class="c1"># fixed_model: Model</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">synthesizer</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">synthesizer</span> <span class="o">=</span> <span class="n">synthesizer</span>

    <span class="k">def</span> <span class="nf">compute_blind_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">attack</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        :param model:</span>
<span class="sd">        :param criterion:</span>
<span class="sd">        :param batch:</span>
<span class="sd">        :param attack: Do not attack at all. Ignore all the parameters</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">clip_batch</span><span class="p">)</span>
        <span class="n">loss_tasks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">loss_tasks</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">if</span> <span class="n">attack</span> <span class="k">else</span> <span class="p">[</span><span class="s1">&#39;normal&#39;</span><span class="p">]</span>
        <span class="n">batch_back</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">synthesizer</span><span class="o">.</span><span class="n">make_backdoor_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">attack</span><span class="o">=</span><span class="n">attack</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">loss_threshold</span> <span class="ow">and</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_hist</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">loss_threshold</span>
                                           <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_hist</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">batch_history_len</span><span class="p">):</span>
            <span class="n">loss_tasks</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;normal&#39;</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_tasks</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">loss_values</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">compute_all_losses_and_grads</span><span class="p">(</span>
                <span class="n">loss_tasks</span><span class="p">,</span>
                <span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_back</span><span class="p">,</span> <span class="n">compute_grad</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">loss_balance</span> <span class="o">==</span> <span class="s1">&#39;MGDA&#39;</span><span class="p">:</span>

            <span class="n">loss_values</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">compute_all_losses_and_grads</span><span class="p">(</span>
                <span class="n">loss_tasks</span><span class="p">,</span>
                <span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_back</span><span class="p">,</span> <span class="n">compute_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_tasks</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">MGDASolver</span><span class="o">.</span><span class="n">get_scales</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">loss_values</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">mgda_normalize</span><span class="p">,</span>
                                              <span class="n">loss_tasks</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">loss_balance</span> <span class="o">==</span> <span class="s1">&#39;fixed&#39;</span><span class="p">:</span>
            <span class="n">loss_values</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">compute_all_losses_and_grads</span><span class="p">(</span>
                <span class="n">loss_tasks</span><span class="p">,</span>
                <span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_back</span><span class="p">,</span> <span class="n">compute_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">loss_tasks</span><span class="p">:</span>
                <span class="n">scale</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">fixed_scales</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Please choose between `MGDA` and `fixed`.&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_tasks</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="p">{</span><span class="n">loss_tasks</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="mf">1.0</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_hist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_values</span><span class="p">[</span><span class="s1">&#39;normal&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_hist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_hist</span><span class="p">[</span><span class="o">-</span><span class="mi">1000</span><span class="p">:]</span>
        <span class="n">blind_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_losses</span><span class="p">(</span><span class="n">loss_tasks</span><span class="p">,</span> <span class="n">loss_values</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">blind_loss</span>

    <span class="k">def</span> <span class="nf">scale_losses</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss_tasks</span><span class="p">,</span> <span class="n">loss_values</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
        <span class="n">blind_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">it</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">loss_tasks</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">running_losses</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_values</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">running_scales</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">it</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">blind_loss</span> <span class="o">=</span> <span class="n">scale</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">*</span> <span class="n">loss_values</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">blind_loss</span> <span class="o">+=</span> <span class="n">scale</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">*</span> <span class="n">loss_values</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">running_losses</span><span class="p">[</span><span class="s1">&#39;total&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">blind_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">blind_loss</span>


<span class="c1"># Credits to Ozan Sener</span>
<span class="c1"># https://github.com/intel-isl/MultiObjectiveOptimization</span>
<span class="k">class</span> <span class="nc">MGDASolver</span><span class="p">:</span>
    <span class="n">MAX_ITER</span> <span class="o">=</span> <span class="mi">250</span>
    <span class="n">STOP_CRIT</span> <span class="o">=</span> <span class="mf">1e-5</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_min_norm_element_from2</span><span class="p">(</span><span class="n">v1v1</span><span class="p">,</span> <span class="n">v1v2</span><span class="p">,</span> <span class="n">v2v2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Analytical solution for min_{c} |cx_1 + (1-c)x_2|_2^2</span>
<span class="sd">        d is the distance (objective) optimzed</span>
<span class="sd">        v1v1 = &lt;x1,x1&gt;</span>
<span class="sd">        v1v2 = &lt;x1,x2&gt;</span>
<span class="sd">        v2v2 = &lt;x2,x2&gt;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">v1v2</span> <span class="o">&gt;=</span> <span class="n">v1v1</span><span class="p">:</span>
            <span class="c1"># Case: Fig 1, third column</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.999</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="n">v1v1</span>
            <span class="k">return</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">cost</span>
        <span class="k">if</span> <span class="n">v1v2</span> <span class="o">&gt;=</span> <span class="n">v2v2</span><span class="p">:</span>
            <span class="c1"># Case: Fig 1, first column</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.001</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="n">v2v2</span>
            <span class="k">return</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">cost</span>
        <span class="c1"># Case: Fig 1, second column</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="p">((</span><span class="n">v1v2</span> <span class="o">-</span> <span class="n">v2v2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">v1v1</span> <span class="o">+</span> <span class="n">v2v2</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">v1v2</span><span class="p">))</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">v2v2</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="p">(</span><span class="n">v1v2</span> <span class="o">-</span> <span class="n">v2v2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">cost</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_min_norm_2d</span><span class="p">(</span><span class="n">vecs</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">dps</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Find the minimum norm solution as combination of two points</span>
<span class="sd">        This is correct only in 2D</span>
<span class="sd">        ie. min_c |\sum c_i x_i|_2^2 st. \sum c_i = 1 , 1 &gt;= c_1 &gt;= 0</span>
<span class="sd">        for all i, c_i + c_j = 1.0 for some i, j</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dmin</span> <span class="o">=</span> <span class="mf">1e8</span>
        <span class="n">sol</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vecs</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vecs</span><span class="p">)):</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dps</span><span class="p">:</span>
                    <span class="n">dps</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vecs</span><span class="p">[</span><span class="n">i</span><span class="p">])):</span>
                        <span class="n">dps</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vecs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                                                 <span class="n">vecs</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                    <span class="n">dps</span><span class="p">[(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">dps</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dps</span><span class="p">:</span>
                    <span class="n">dps</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vecs</span><span class="p">[</span><span class="n">i</span><span class="p">])):</span>
                        <span class="n">dps</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">)]</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vecs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                                                 <span class="n">vecs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dps</span><span class="p">:</span>
                    <span class="n">dps</span><span class="p">[(</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vecs</span><span class="p">[</span><span class="n">i</span><span class="p">])):</span>
                        <span class="n">dps</span><span class="p">[(</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vecs</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                                                 <span class="n">vecs</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                <span class="n">c</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">MGDASolver</span><span class="o">.</span><span class="n">_min_norm_element_from2</span><span class="p">(</span><span class="n">dps</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">)],</span>
                                                          <span class="n">dps</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)],</span>
                                                          <span class="n">dps</span><span class="p">[(</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">)])</span>
                <span class="k">if</span> <span class="n">d</span> <span class="o">&lt;</span> <span class="n">dmin</span><span class="p">:</span>
                    <span class="n">dmin</span> <span class="o">=</span> <span class="n">d</span>
                    <span class="n">sol</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">sol</span><span class="p">,</span> <span class="n">dps</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_projection2simplex</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given y, it solves argmin_z |y-z|_2 st \sum z = 1 , 1 &gt;= z_i &gt;= 0 for all i</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">sorted_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">tmpsum</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">tmax_f</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">m</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">tmpsum</span> <span class="o">+=</span> <span class="n">sorted_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">tmax</span> <span class="o">=</span> <span class="p">(</span><span class="n">tmpsum</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">tmax</span> <span class="o">&gt;</span> <span class="n">sorted_y</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]:</span>
                <span class="n">tmax_f</span> <span class="o">=</span> <span class="n">tmax</span>
                <span class="k">break</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">tmax_f</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_next_point</span><span class="p">(</span><span class="n">cur_val</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="n">proj_grad</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>
        <span class="n">tm1</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">cur_val</span><span class="p">[</span><span class="n">proj_grad</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">proj_grad</span><span class="p">[</span><span class="n">proj_grad</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">tm2</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">cur_val</span><span class="p">[</span><span class="n">proj_grad</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">proj_grad</span><span class="p">[</span><span class="n">proj_grad</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">])</span>

        <span class="n">skippers</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tm1</span> <span class="o">&lt;</span> <span class="mf">1e-7</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tm2</span> <span class="o">&lt;</span> <span class="mf">1e-7</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tm1</span><span class="p">[</span><span class="n">tm1</span> <span class="o">&gt;</span> <span class="mf">1e-7</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">tm1</span><span class="p">[</span><span class="n">tm1</span> <span class="o">&gt;</span> <span class="mf">1e-7</span><span class="p">])</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tm2</span><span class="p">[</span><span class="n">tm2</span> <span class="o">&gt;</span> <span class="mf">1e-7</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">tm2</span><span class="p">[</span><span class="n">tm2</span> <span class="o">&gt;</span> <span class="mf">1e-7</span><span class="p">]))</span>

        <span class="n">next_point</span> <span class="o">=</span> <span class="n">proj_grad</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="n">cur_val</span>
        <span class="n">next_point</span> <span class="o">=</span> <span class="n">MGDASolver</span><span class="o">.</span><span class="n">_projection2simplex</span><span class="p">(</span><span class="n">next_point</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_point</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">find_min_norm_element</span><span class="p">(</span><span class="n">vecs</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a list of vectors (vecs), this method finds the minimum norm</span>
<span class="sd">        element in the convex hull as min |u|_2 st. u = \sum c_i vecs[i]</span>
<span class="sd">        and \sum c_i = 1. It is quite geometric, and the main idea is the</span>
<span class="sd">        fact that if d_{ij} = min |u|_2 st u = c x_i + (1-c) x_j; the solution</span>
<span class="sd">        lies in (0, d_{i,j})Hence, we find the best 2-task solution , and</span>
<span class="sd">        then run the projected gradient descent until convergence</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Solution lying at the combination of two points</span>
        <span class="n">dps</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">init_sol</span><span class="p">,</span> <span class="n">dps</span> <span class="o">=</span> <span class="n">MGDASolver</span><span class="o">.</span><span class="n">_min_norm_2d</span><span class="p">(</span><span class="n">vecs</span><span class="p">,</span> <span class="n">dps</span><span class="p">)</span>

        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vecs</span><span class="p">)</span>
        <span class="n">sol_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="n">sol_vec</span><span class="p">[</span><span class="n">init_sol</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">init_sol</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">sol_vec</span><span class="p">[</span><span class="n">init_sol</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">init_sol</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="c1"># This is optimal for n=2, so return the solution</span>
            <span class="k">return</span> <span class="n">sol_vec</span><span class="p">,</span> <span class="n">init_sol</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

        <span class="n">iter_count</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">grad_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                <span class="n">grad_mat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">dps</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span>

        <span class="k">while</span> <span class="n">iter_count</span> <span class="o">&lt;</span> <span class="n">MGDASolver</span><span class="o">.</span><span class="n">MAX_ITER</span><span class="p">:</span>
            <span class="n">grad_dir</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">grad_mat</span><span class="p">,</span> <span class="n">sol_vec</span><span class="p">)</span>
            <span class="n">new_point</span> <span class="o">=</span> <span class="n">MGDASolver</span><span class="o">.</span><span class="n">_next_point</span><span class="p">(</span><span class="n">sol_vec</span><span class="p">,</span> <span class="n">grad_dir</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
            <span class="c1"># Re-compute the inner products for line search</span>
            <span class="n">v1v1</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">v1v2</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">v2v2</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                    <span class="n">v1v1</span> <span class="o">+=</span> <span class="n">sol_vec</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">sol_vec</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">dps</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span>
                    <span class="n">v1v2</span> <span class="o">+=</span> <span class="n">sol_vec</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">new_point</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">dps</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span>
                    <span class="n">v2v2</span> <span class="o">+=</span> <span class="n">new_point</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">new_point</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">dps</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span>
            <span class="n">nc</span><span class="p">,</span> <span class="n">nd</span> <span class="o">=</span> <span class="n">MGDASolver</span><span class="o">.</span><span class="n">_min_norm_element_from2</span><span class="p">(</span><span class="n">v1v1</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                                                        <span class="n">v1v2</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                                                        <span class="n">v2v2</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="c1"># try:</span>
            <span class="n">new_sol_vec</span> <span class="o">=</span> <span class="n">nc</span> <span class="o">*</span> <span class="n">sol_vec</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">nc</span><span class="p">)</span> <span class="o">*</span> <span class="n">new_point</span>
            <span class="c1"># except AttributeError:</span>
            <span class="c1">#     logging.debug(sol_vec)</span>
            <span class="n">change</span> <span class="o">=</span> <span class="n">new_sol_vec</span> <span class="o">-</span> <span class="n">sol_vec</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">change</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">MGDASolver</span><span class="o">.</span><span class="n">STOP_CRIT</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">sol_vec</span><span class="p">,</span> <span class="n">nd</span>
            <span class="n">sol_vec</span> <span class="o">=</span> <span class="n">new_sol_vec</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">find_min_norm_element_FW</span><span class="p">(</span><span class="n">vecs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a list of vectors (vecs), this method finds the minimum norm</span>
<span class="sd">        element in the convex hull</span>
<span class="sd">        as min |u|_2 st. u = \sum c_i vecs[i] and \sum c_i = 1.</span>
<span class="sd">        It is quite geometric, and the main idea is the fact that if</span>
<span class="sd">        d_{ij} = min |u|_2 st u = c x_i + (1-c) x_j; the solution lies</span>
<span class="sd">        in (0, d_{i,j})Hence, we find the best 2-task solution, and then</span>
<span class="sd">        run the Frank Wolfe until convergence</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Solution lying at the combination of two points</span>
        <span class="n">dps</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">init_sol</span><span class="p">,</span> <span class="n">dps</span> <span class="o">=</span> <span class="n">MGDASolver</span><span class="o">.</span><span class="n">_min_norm_2d</span><span class="p">(</span><span class="n">vecs</span><span class="p">,</span> <span class="n">dps</span><span class="p">)</span>

        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vecs</span><span class="p">)</span>
        <span class="n">sol_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="n">sol_vec</span><span class="p">[</span><span class="n">init_sol</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">init_sol</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">sol_vec</span><span class="p">[</span><span class="n">init_sol</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">init_sol</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="c1"># This is optimal for n=2, so return the solution</span>
            <span class="k">return</span> <span class="n">sol_vec</span><span class="p">,</span> <span class="n">init_sol</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

        <span class="n">iter_count</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">grad_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                <span class="n">grad_mat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">dps</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span>

        <span class="k">while</span> <span class="n">iter_count</span> <span class="o">&lt;</span> <span class="n">MGDASolver</span><span class="o">.</span><span class="n">MAX_ITER</span><span class="p">:</span>
            <span class="n">t_iter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">grad_mat</span><span class="p">,</span> <span class="n">sol_vec</span><span class="p">))</span>

            <span class="n">v1v1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">sol_vec</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">grad_mat</span><span class="p">,</span> <span class="n">sol_vec</span><span class="p">))</span>
            <span class="n">v1v2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">sol_vec</span><span class="p">,</span> <span class="n">grad_mat</span><span class="p">[:,</span> <span class="n">t_iter</span><span class="p">])</span>
            <span class="n">v2v2</span> <span class="o">=</span> <span class="n">grad_mat</span><span class="p">[</span><span class="n">t_iter</span><span class="p">,</span> <span class="n">t_iter</span><span class="p">]</span>

            <span class="n">nc</span><span class="p">,</span> <span class="n">nd</span> <span class="o">=</span> <span class="n">MGDASolver</span><span class="o">.</span><span class="n">_min_norm_element_from2</span><span class="p">(</span><span class="n">v1v1</span><span class="p">,</span> <span class="n">v1v2</span><span class="p">,</span> <span class="n">v2v2</span><span class="p">)</span>
            <span class="n">new_sol_vec</span> <span class="o">=</span> <span class="n">nc</span> <span class="o">*</span> <span class="n">sol_vec</span>
            <span class="n">new_sol_vec</span><span class="p">[</span><span class="n">t_iter</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">nc</span>

            <span class="n">change</span> <span class="o">=</span> <span class="n">new_sol_vec</span> <span class="o">-</span> <span class="n">sol_vec</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">change</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">MGDASolver</span><span class="o">.</span><span class="n">STOP_CRIT</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">sol_vec</span><span class="p">,</span> <span class="n">nd</span>
            <span class="n">sol_vec</span> <span class="o">=</span> <span class="n">new_sol_vec</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">get_scales</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">normalization_type</span><span class="p">,</span> <span class="n">tasks</span><span class="p">):</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">gn</span> <span class="o">=</span> <span class="n">gradient_normalizers</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">normalization_type</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tasks</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">gr_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">grads</span><span class="p">[</span><span class="n">t</span><span class="p">])):</span>
                <span class="n">grads</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="n">gr_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="n">gr_i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">gn</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>
        <span class="n">sol</span><span class="p">,</span> <span class="n">min_norm</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">find_min_norm_element</span><span class="p">([</span><span class="n">grads</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tasks</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">zi</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tasks</span><span class="p">):</span>
            <span class="n">scale</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">sol</span><span class="p">[</span><span class="n">zi</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">scale</span>


<span class="k">def</span> <span class="nf">create_table</span><span class="p">(</span><span class="n">params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="s2">&quot;| name | value | </span><span class="se">\n</span><span class="s2"> |-----|-----|&quot;</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">data</span> <span class="o">+=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;| </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2"> |&quot;</span>

    <span class="k">return</span> <span class="n">data</span>


<span class="k">class</span> <span class="nc">PatternSynthesizer</span><span class="p">(</span><span class="n">Synthesizer</span><span class="p">):</span>
    <span class="n">pattern_tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">10.</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">10.</span><span class="p">,</span> <span class="o">-</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">10.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]</span>
    <span class="p">])</span>
    <span class="s2">&quot;Just some random 2D pattern.&quot;</span>

    <span class="n">x_top</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="s2">&quot;X coordinate to put the backdoor into.&quot;</span>
    <span class="n">y_top</span> <span class="o">=</span> <span class="mi">23</span>
    <span class="s2">&quot;Y coordinate to put the backdoor into.&quot;</span>

    <span class="n">mask_value</span> <span class="o">=</span> <span class="o">-</span><span class="mi">10</span>
    <span class="s2">&quot;A tensor coordinate with this value won&#39;t be applied to the image.&quot;</span>

    <span class="n">resize_scale</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="s2">&quot;If the pattern is dynamically placed, resize the pattern.&quot;</span>

    <span class="n">mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="s2">&quot;A mask used to combine backdoor pattern with the original image.&quot;</span>

    <span class="n">pattern</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="s2">&quot;A tensor of the `input.shape` filled with `mask_value` except backdoor.&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task</span><span class="p">:</span> <span class="n">Task</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">task</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">make_pattern</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pattern_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_top</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_top</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">make_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pattern_tensor</span><span class="p">,</span> <span class="n">x_top</span><span class="p">,</span> <span class="n">y_top</span><span class="p">):</span>
        <span class="n">full_image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">input_shape</span><span class="p">)</span>
        <span class="n">full_image</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask_value</span><span class="p">)</span>

        <span class="n">x_bot</span> <span class="o">=</span> <span class="n">x_top</span> <span class="o">+</span> <span class="n">pattern_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y_bot</span> <span class="o">=</span> <span class="n">y_top</span> <span class="o">+</span> <span class="n">pattern_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">x_bot</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">or</span> \
                <span class="n">y_bot</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Position of backdoor outside image limits:&#39;</span>
                             <span class="sa">f</span><span class="s1">&#39;image: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">input_shape</span><span class="si">}</span><span class="s1">, but backdoor&#39;</span>
                             <span class="sa">f</span><span class="s1">&#39;ends at (</span><span class="si">{</span><span class="n">x_bot</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">y_bot</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

        <span class="n">full_image</span><span class="p">[:,</span> <span class="n">x_top</span><span class="p">:</span><span class="n">x_bot</span><span class="p">,</span> <span class="n">y_top</span><span class="p">:</span><span class="n">y_bot</span><span class="p">]</span> <span class="o">=</span> <span class="n">pattern_tensor</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">full_image</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_value</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pattern</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">full_image</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">synthesize_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">attack_portion</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">pattern</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">()</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">inputs</span><span class="p">[:</span><span class="n">attack_portion</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">mask</span><span class="p">)</span> <span class="o">*</span> \
                                        <span class="n">batch</span><span class="o">.</span><span class="n">inputs</span><span class="p">[:</span><span class="n">attack_portion</span><span class="p">]</span> <span class="o">+</span> \
                                        <span class="n">mask</span> <span class="o">*</span> <span class="n">pattern</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">synthesize_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">attack_portion</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">labels</span><span class="p">[:</span><span class="n">attack_portion</span><span class="p">]</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">backdoor_label</span><span class="p">)</span>

        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">get_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">backdoor_dynamic_position</span><span class="p">:</span>
            <span class="n">resize</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">resize_scale</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">resize_scale</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">pattern</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pattern_tensor</span>
            <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">pattern</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">hflip</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">transform_to_image</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
            <span class="n">pattern</span> <span class="o">=</span> <span class="n">transform_to_tensor</span><span class="p">(</span>
                <span class="n">functional</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                  <span class="n">resize</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

            <span class="n">x</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> \
                               <span class="o">-</span> <span class="n">pattern</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> \
                               <span class="o">-</span> <span class="n">pattern</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_pattern</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pattern</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span>


<span class="k">class</span> <span class="nc">Cifar10Task</span><span class="p">(</span><span class="n">Task</span><span class="p">):</span>
    <span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.4914</span><span class="p">,</span> <span class="mf">0.4822</span><span class="p">,</span> <span class="mf">0.4465</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.247</span><span class="p">,</span> <span class="mf">0.243</span><span class="p">,</span> <span class="mf">0.261</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_cifar_data</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">load_cifar_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">train_dataset_without_transform</span><span class="p">,</span> \
        <span class="n">transform_train</span><span class="p">,</span> \
        <span class="n">train_label_transform</span><span class="p">,</span> \
        <span class="n">test_dataset_without_transform</span><span class="p">,</span> \
        <span class="n">transform_test</span><span class="p">,</span> \
        <span class="n">test_label_transform</span> <span class="o">=</span> <span class="n">dataset_and_transform_generate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>

        <span class="n">clean_train_dataset_with_transform</span> <span class="o">=</span> <span class="n">dataset_wrapper_with_transform</span><span class="p">(</span>
            <span class="n">train_dataset_without_transform</span><span class="p">,</span>
            <span class="n">transform_train</span><span class="p">,</span>
            <span class="n">train_label_transform</span>
        <span class="p">)</span>

        <span class="n">clean_test_dataset_with_transform</span> <span class="o">=</span> <span class="n">dataset_wrapper_with_transform</span><span class="p">(</span>
            <span class="n">test_dataset_without_transform</span><span class="p">,</span>
            <span class="n">transform_test</span><span class="p">,</span>
            <span class="n">test_label_transform</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">clean_train_dataset_with_transform</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                                       <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                       <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                       <span class="n">pin_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">,</span>
                                       <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">clean_test_dataset_with_transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span><span class="p">,</span>
                                      <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">test_batch_size</span><span class="p">,</span>
                                      <span class="n">pin_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">,</span>
                                      <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)</span>

        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">generate_cls_model</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">image_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">img_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;,&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
            <span class="n">net</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span>
                <span class="n">net</span><span class="p">,</span>
                <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">device</span><span class="p">[</span><span class="mi">5</span><span class="p">:]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)]</span>  <span class="c1"># eg. &quot;cuda:2,3,7&quot; -&gt; [2,3,7]</span>
            <span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;net data parallel&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;cuda:</span><span class="si">{</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">device</span><span class="p">[</span><span class="mi">5</span><span class="p">:]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="s2">&quot;,&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">device</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">device</span>
            <span class="c1"># since DataParallel only allow .to(&quot;cuda&quot;)</span>
        <span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>

        <span class="k">return</span> <span class="n">net</span>


<span class="k">class</span> <span class="nc">Helper</span><span class="p">:</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">Params</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">task</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Task</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">synthesizer</span><span class="p">:</span> <span class="n">Synthesizer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">attack</span><span class="p">:</span> <span class="n">Attack</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">tb_writer</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">Params</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">times</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;backward&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(),</span> <span class="s1">&#39;forward&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(),</span> <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(),</span>
                      <span class="s1">&#39;scales&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(),</span> <span class="s1">&#39;total&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(),</span> <span class="s1">&#39;poison&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">()}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">make_task</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">make_synthesizer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attack</span> <span class="o">=</span> <span class="n">Attack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">synthesizer</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">make_task</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task</span> <span class="o">=</span> <span class="n">Cifar10Task</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">make_synthesizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">synthesizer</span> <span class="o">=</span> <span class="n">PatternSynthesizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">is_best</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;checkpoint.pth.tar&#39;</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">save_model</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">is_best</span><span class="p">:</span>
            <span class="n">copyfile</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;model_best.pth.tar&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">flush_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">scalar_value</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">flush_writer</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">report_training_losses_scales</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">report_train_loss</span> <span class="ow">or</span> \
                <span class="n">batch_id</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">log_interval</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="n">total_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train_loader</span><span class="p">)</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span>
                  <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">running_losses</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
        <span class="n">scales</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span>
                  <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">running_scales</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s1">&#39;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="s1">3d</span><span class="si">}</span><span class="s1">. &#39;</span>
            <span class="sa">f</span><span class="s1">&#39;Batch: </span><span class="si">{</span><span class="n">batch_id</span><span class="si">:</span><span class="s1">5d</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">total_batches</span><span class="si">}</span><span class="s1">. &#39;</span>
            <span class="sa">f</span><span class="s1">&#39; Losses: </span><span class="si">{</span><span class="n">losses</span><span class="si">}</span><span class="s1">.&#39;</span>
            <span class="sa">f</span><span class="s1">&#39; Scales: </span><span class="si">{</span><span class="n">scales</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">running_losses</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch</span> <span class="o">*</span> <span class="n">total_batches</span> <span class="o">+</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">values</span><span class="p">),</span>
                      <span class="sa">f</span><span class="s1">&#39;Train/Loss_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">running_scales</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch</span> <span class="o">*</span> <span class="n">total_batches</span> <span class="o">+</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">values</span><span class="p">),</span>
                      <span class="sa">f</span><span class="s1">&#39;Train/Scale_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">running_losses</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">running_scales</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">hlpr</span><span class="p">:</span> <span class="n">Helper</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">attack</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">hlpr</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">criterion</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="n">batch_loss_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)):</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">hlpr</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">get_batch</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">amp</span><span class="p">):</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">hlpr</span><span class="o">.</span><span class="n">attack</span><span class="o">.</span><span class="n">compute_blind_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">attack</span><span class="p">)</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">batch_loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">hlpr</span><span class="o">.</span><span class="n">report_training_losses_scales</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">hlpr</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">max_batch_id</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="n">one_epoch_loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">batch_loss_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_loss_list</span><span class="p">)</span>

    <span class="n">scheduler</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">hlpr</span><span class="o">.</span><span class="n">task</span><span class="p">,</span> <span class="s2">&quot;scheduler&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scheduler</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">):</span>
            <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">one_epoch_loss</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;scheduler step, </span><span class="si">{</span><span class="n">scheduler</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">one_epoch_loss</span>


<span class="k">def</span> <span class="nf">hlpr_test</span><span class="p">(</span><span class="n">hlpr</span><span class="p">:</span> <span class="n">Helper</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">backdoor</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">hlpr</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">model</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">hlpr</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">hlpr</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">test_loader</span><span class="p">)):</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">hlpr</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">get_batch</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">backdoor</span><span class="p">:</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="n">hlpr</span><span class="o">.</span><span class="n">attack</span><span class="o">.</span><span class="n">synthesizer</span><span class="o">.</span><span class="n">make_backdoor_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span>
                                                                    <span class="n">test</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                                    <span class="n">attack</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">hlpr</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">accumulate_metrics</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">batch</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">metric</span> <span class="o">=</span> <span class="n">hlpr</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">report_metrics</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span>
                                      <span class="n">prefix</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Backdoor </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">backdoor</span><span class="p">)</span><span class="si">:</span><span class="s1">5s</span><span class="si">}</span><span class="s1">. Epoch: &#39;</span><span class="p">,</span>
                                      <span class="n">tb_writer</span><span class="o">=</span><span class="n">hlpr</span><span class="o">.</span><span class="n">tb_writer</span><span class="p">,</span>
                                      <span class="n">tb_prefix</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Test_backdoor_</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">backdoor</span><span class="p">)</span><span class="si">:</span><span class="s1">5s</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">metric</span>


<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">hlpr</span><span class="p">,</span> <span class="n">clean_test_dataloader</span><span class="p">,</span> <span class="n">bd_test_dataloader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">scaler</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">GradScaler</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="n">hlpr</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">amp</span><span class="p">)</span>

    <span class="n">acc</span> <span class="o">=</span> <span class="n">hlpr_test</span><span class="p">(</span><span class="n">hlpr</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">backdoor</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">clean_test_loss_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">bd_test_loss_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_acc_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_asr_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_ra_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">train_loss_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">agg</span> <span class="o">=</span> <span class="n">Metric_Aggregator</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hlpr</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">start_epoch</span><span class="p">,</span>
                       <span class="n">hlpr</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">one_epoch_train_loss</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">hlpr</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">hlpr</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">hlpr</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
                                     <span class="n">hlpr</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
        <span class="n">train_loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">one_epoch_train_loss</span><span class="p">)</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">hlpr_test</span><span class="p">(</span><span class="n">hlpr</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">backdoor</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">hlpr_test</span><span class="p">(</span><span class="n">hlpr</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">backdoor</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1">### My test code start</span>

        <span class="n">clean_metrics</span><span class="p">,</span> \
        <span class="n">clean_test_epoch_predict_list</span><span class="p">,</span> \
        <span class="n">clean_test_epoch_label_list</span><span class="p">,</span> \
            <span class="o">=</span> <span class="n">given_dataloader_test</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">hlpr</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">test_dataloader</span><span class="o">=</span><span class="n">clean_test_dataloader</span><span class="p">,</span>
            <span class="n">criterion</span><span class="o">=</span><span class="n">criterion</span><span class="p">,</span>
            <span class="n">non_blocking</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">non_blocking</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">clean_test_loss_avg_over_batch</span> <span class="o">=</span> <span class="n">clean_metrics</span><span class="p">[</span><span class="s2">&quot;test_loss_avg_over_batch&quot;</span><span class="p">]</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">clean_metrics</span><span class="p">[</span><span class="s2">&quot;test_acc&quot;</span><span class="p">]</span>

        <span class="n">bd_metrics</span><span class="p">,</span> \
        <span class="n">bd_test_epoch_predict_list</span><span class="p">,</span> \
        <span class="n">bd_test_epoch_label_list</span><span class="p">,</span> \
        <span class="n">bd_test_epoch_original_index_list</span><span class="p">,</span> \
        <span class="n">bd_test_epoch_poison_indicator_list</span><span class="p">,</span> \
        <span class="n">bd_test_epoch_original_targets_list</span> <span class="o">=</span> <span class="n">test_given_dataloader_on_mix</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">hlpr</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">test_dataloader</span><span class="o">=</span><span class="n">bd_test_dataloader</span><span class="p">,</span>
            <span class="n">criterion</span><span class="o">=</span><span class="n">criterion</span><span class="p">,</span>
            <span class="n">non_blocking</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">non_blocking</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">bd_test_loss_avg_over_batch</span> <span class="o">=</span> <span class="n">bd_metrics</span><span class="p">[</span><span class="s2">&quot;test_loss_avg_over_batch&quot;</span><span class="p">]</span>
        <span class="n">test_asr</span> <span class="o">=</span> <span class="n">all_acc</span><span class="p">(</span><span class="n">bd_test_epoch_predict_list</span><span class="p">,</span> <span class="n">bd_test_epoch_label_list</span><span class="p">)</span>
        <span class="n">test_ra</span> <span class="o">=</span> <span class="n">all_acc</span><span class="p">(</span><span class="n">bd_test_epoch_predict_list</span><span class="p">,</span> <span class="n">bd_test_epoch_original_targets_list</span><span class="p">)</span>

        <span class="n">agg</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
                <span class="s2">&quot;train_epoch_loss_avg_over_batch&quot;</span><span class="p">:</span> <span class="n">one_epoch_train_loss</span><span class="p">,</span>
                <span class="s2">&quot;clean_test_loss_avg_over_batch&quot;</span><span class="p">:</span> <span class="n">clean_test_loss_avg_over_batch</span><span class="p">,</span>
                <span class="s2">&quot;bd_test_loss_avg_over_batch&quot;</span><span class="p">:</span> <span class="n">bd_test_loss_avg_over_batch</span><span class="p">,</span>
                <span class="s2">&quot;test_acc&quot;</span><span class="p">:</span> <span class="n">test_acc</span><span class="p">,</span>
                <span class="s2">&quot;test_asr&quot;</span><span class="p">:</span> <span class="n">test_asr</span><span class="p">,</span>
                <span class="s2">&quot;test_ra&quot;</span><span class="p">:</span> <span class="n">test_ra</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>

        <span class="n">clean_test_loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clean_test_loss_avg_over_batch</span><span class="p">)</span>
        <span class="n">bd_test_loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bd_test_loss_avg_over_batch</span><span class="p">)</span>
        <span class="n">test_acc_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_acc</span><span class="p">)</span>
        <span class="n">test_asr_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_asr</span><span class="p">)</span>
        <span class="n">test_ra_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_ra</span><span class="p">)</span>

        <span class="n">plot_loss</span><span class="p">(</span>
            <span class="n">train_loss_list</span><span class="p">,</span>
            <span class="n">clean_test_loss_list</span><span class="p">,</span>
            <span class="n">bd_test_loss_list</span><span class="p">,</span>
            <span class="n">args</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span>
            <span class="s2">&quot;loss_metric_plots&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">plot_acc_like_metric</span><span class="p">(</span>
            <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span>
            <span class="n">test_acc_list</span><span class="p">,</span>
            <span class="n">test_asr_list</span><span class="p">,</span>
            <span class="n">test_ra_list</span><span class="p">,</span>
            <span class="n">args</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span>
            <span class="s2">&quot;loss_metric_plots&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">agg</span><span class="o">.</span><span class="n">to_dataframe</span><span class="p">()</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">save_path</span><span class="si">}</span><span class="s2">/attack_df.csv&quot;</span><span class="p">)</span>

    <span class="n">agg</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">save_path</span><span class="si">}</span><span class="s2">/attack_df_summary.csv&quot;</span><span class="p">)</span>

    <span class="c1">### My test code end</span>


<span class="k">class</span> <span class="nc">AddMaskPatchTrigger</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">trigger_array</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
                 <span class="n">mask_array</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
                 <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trigger_array</span> <span class="o">=</span> <span class="n">trigger_array</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_array</span> <span class="o">=</span> <span class="n">mask_array</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">image_serial_id</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_trigger</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_trigger</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">img</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_array</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">trigger_array</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_array</span>


<span class="k">def</span> <span class="nf">gradient_normalizers</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">normalization_type</span><span class="p">):</span>
    <span class="n">gn</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">normalization_type</span> <span class="o">==</span> <span class="s1">&#39;l2&#39;</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">:</span>
            <span class="n">gn</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">gr</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">data</span> <span class="k">for</span> <span class="n">gr</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">[</span><span class="n">t</span><span class="p">]])</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
    <span class="k">elif</span> <span class="n">normalization_type</span> <span class="o">==</span> <span class="s1">&#39;loss&#39;</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">:</span>
            <span class="n">gn</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="mf">10.0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">normalization_type</span> <span class="o">==</span> <span class="s1">&#39;loss+&#39;</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">:</span>
            <span class="n">gn</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">gr</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">data</span> <span class="k">for</span> <span class="n">gr</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">[</span><span class="n">t</span><span class="p">]])</span><span class="o">.</span><span class="n">sum</span><span class="p">()),</span>
                        <span class="mi">10</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">normalization_type</span> <span class="o">==</span> <span class="s1">&#39;none&#39;</span> <span class="ow">or</span> <span class="n">normalization_type</span> <span class="o">==</span> <span class="s1">&#39;eq&#39;</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">:</span>
            <span class="n">gn</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;ERROR: Invalid Normalization Type&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gn</span>


<span class="k">class</span> <span class="nc">blendedImageAttack_on_batch</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_image</span><span class="p">,</span> <span class="n">blended_rate</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_image</span> <span class="o">=</span> <span class="n">target_image</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blended_rate</span> <span class="o">=</span> <span class="n">blended_rate</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">image_serial_id</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_trigger</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_trigger</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">blended_rate</span><span class="p">)</span> <span class="o">*</span> <span class="n">img</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blended_rate</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_image</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>  <span class="c1"># use the broadcast</span>


<span class="k">class</span> <span class="nc">batchwise_label_transform</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    idea : any label -&gt; fix_target</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">label_transform</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_transform</span> <span class="o">=</span> <span class="n">label_transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">label_transform</span><span class="p">(</span><span class="n">original_label</span><span class="p">)</span> <span class="k">for</span> <span class="n">original_label</span> <span class="ow">in</span> <span class="n">batch_labels</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>


<div class="viewcode-block" id="Blind"><a class="viewcode-back" href="../../generated/attack.Blind.html#attack.Blind">[docs]</a><span class="k">class</span> <span class="nc">Blind</span><span class="p">(</span><span class="n">BadNet</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">set_bd_args</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">:</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--attack&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="p">)</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--attack_target&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                            <span class="n">help</span><span class="o">=</span><span class="s1">&#39;target class in all2one attack&#39;</span><span class="p">)</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--attack_label_trans&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                            <span class="n">help</span><span class="o">=</span><span class="s1">&#39;which type of label modification in backdoor attack&#39;</span>
                            <span class="p">)</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--weight_loss_balance_mode&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--mgda_normalize&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--fix_scale_normal_weight&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--fix_scale_backdoor_weight&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

        <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--batch_history_len&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;len of tracking history to compute when training is stable, so we start to attack&quot;</span><span class="p">)</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--backdoor_batch_loss_threshold&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                            <span class="n">help</span><span class="o">=</span><span class="s2">&quot;threshold for when training is stable, so we start to attack&quot;</span><span class="p">)</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--bd_yaml_path&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__file__</span><span class="p">))</span><span class="o">+</span><span class="s2">&quot;/&quot;</span><span class="o">+</span><span class="s1">&#39;../config/attack/blind/default.yaml&#39;</span><span class="p">,</span>
                            <span class="n">help</span><span class="o">=</span><span class="s1">&#39;path for yaml file provide additional default attributes&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">parser</span>

<div class="viewcode-block" id="Blind.stage1_non_training_data_prepare"><a class="viewcode-back" href="../../generated/attack.Blind.html#attack.Blind.stage1_non_training_data_prepare">[docs]</a>    <span class="k">def</span> <span class="nf">stage1_non_training_data_prepare</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;stage1 start&quot;</span><span class="p">)</span>

        <span class="k">assert</span> <span class="s1">&#39;args&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span>
        <span class="n">args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span>

        <span class="n">train_dataset_without_transform</span><span class="p">,</span> \
        <span class="n">train_img_transform</span><span class="p">,</span> \
        <span class="n">train_label_transform</span><span class="p">,</span> \
        <span class="n">test_dataset_without_transform</span><span class="p">,</span> \
        <span class="n">test_img_transform</span><span class="p">,</span> \
        <span class="n">test_label_transform</span><span class="p">,</span> \
        <span class="n">clean_train_dataset_with_transform</span><span class="p">,</span> \
        <span class="n">clean_train_dataset_targets</span><span class="p">,</span> \
        <span class="n">clean_test_dataset_with_transform</span><span class="p">,</span> \
        <span class="n">clean_test_dataset_targets</span> \
            <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">benign_prepare</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trans</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">(),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">img_size</span><span class="p">[:</span><span class="mi">2</span><span class="p">]),</span>  <span class="c1"># (32, 32)</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
        <span class="p">])</span>

        <span class="n">trigger_pattern_np</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>

            <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">10.</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="o">-</span><span class="mf">10.</span><span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">10.</span><span class="p">,</span> <span class="o">-</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">10.</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="o">-</span><span class="mf">10.</span><span class="p">],</span>
            <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mi">255</span><span class="p">]</span>
        <span class="p">])</span>
        <span class="n">trigger_pattern_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">trigger_pattern_np</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">args</span><span class="o">.</span><span class="n">input_channel</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">trigger_full_size_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">args</span><span class="o">.</span><span class="n">input_height</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">input_width</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">input_channel</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">x_top</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="n">y_top</span> <span class="o">=</span> <span class="mi">23</span>
        <span class="n">trigger_full_size_np</span><span class="p">[</span>
        <span class="n">x_top</span><span class="p">:</span> <span class="n">x_top</span> <span class="o">+</span> <span class="n">trigger_pattern_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">y_top</span><span class="p">:</span> <span class="n">y_top</span> <span class="o">+</span> <span class="n">trigger_pattern_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">:</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">trigger_pattern_np</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trigger_full_size_np</span> <span class="o">=</span> <span class="n">trigger_full_size_np</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">trigger_full_size_np</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">10</span><span class="p">)</span>

        <span class="n">test_bd_transform</span> <span class="o">=</span> <span class="n">general_compose</span><span class="p">([</span>
            <span class="p">(</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">img_size</span><span class="p">[:</span><span class="mi">2</span><span class="p">]),</span> <span class="kc">False</span><span class="p">),</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
            <span class="p">(</span><span class="n">AddMaskPatchTrigger</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">trigger_full_size_np</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="p">,</span> <span class="kc">True</span><span class="p">),</span>
        <span class="p">])</span>

        <span class="n">train_bd_img_transform</span><span class="p">,</span> <span class="n">test_bd_img_transform</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">test_bd_transform</span>

        <span class="c1">### get the backdoor transform on label</span>
        <span class="n">bd_label_transform</span> <span class="o">=</span> <span class="n">bd_attack_label_trans_generate</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bd_label_transform</span> <span class="o">=</span> <span class="n">bd_label_transform</span>

        <span class="c1"># NO poison samples in, just use as clean, real poison is done in batchwise way</span>
        <span class="n">bd_train_dataset</span> <span class="o">=</span> <span class="n">prepro_cls_DatasetBD_v2</span><span class="p">(</span>
            <span class="n">deepcopy</span><span class="p">(</span><span class="n">train_dataset_without_transform</span><span class="p">),</span>
            <span class="n">poison_indicator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">bd_image_pre_transform</span><span class="o">=</span><span class="n">train_bd_img_transform</span><span class="p">,</span>
            <span class="n">bd_label_pre_transform</span><span class="o">=</span><span class="n">bd_label_transform</span><span class="p">,</span>
            <span class="n">save_folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">save_path</span><span class="si">}</span><span class="s2">/bd_train_dataset&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">bd_train_dataset</span><span class="o">.</span><span class="n">getitem_all</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">bd_train_dataset_with_transform</span> <span class="o">=</span> <span class="n">dataset_wrapper_with_transform</span><span class="p">(</span>
            <span class="n">bd_train_dataset</span><span class="p">,</span>
            <span class="n">train_img_transform</span><span class="p">,</span>
            <span class="n">train_label_transform</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1">### decide which img to poison in ASR Test</span>
        <span class="n">test_poison_index</span> <span class="o">=</span> <span class="n">generate_poison_index_from_label_transform</span><span class="p">(</span>
            <span class="n">clean_test_dataset_targets</span><span class="p">,</span>
            <span class="n">label_transform</span><span class="o">=</span><span class="n">bd_label_transform</span><span class="p">,</span>
            <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1">### generate test dataset for ASR</span>
        <span class="n">bd_test_dataset</span> <span class="o">=</span> <span class="n">prepro_cls_DatasetBD_v2</span><span class="p">(</span>
            <span class="n">deepcopy</span><span class="p">(</span><span class="n">test_dataset_without_transform</span><span class="p">),</span>
            <span class="n">poison_indicator</span><span class="o">=</span><span class="n">test_poison_index</span><span class="p">,</span>
            <span class="n">bd_image_pre_transform</span><span class="o">=</span><span class="n">test_bd_img_transform</span><span class="p">,</span>
            <span class="n">bd_label_pre_transform</span><span class="o">=</span><span class="n">bd_label_transform</span><span class="p">,</span>
            <span class="n">save_folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">save_path</span><span class="si">}</span><span class="s2">/bd_test_dataset&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">bd_test_dataset</span><span class="o">.</span><span class="n">subset</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">test_poison_index</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="n">bd_test_dataset_with_transform</span> <span class="o">=</span> <span class="n">dataset_wrapper_with_transform</span><span class="p">(</span>
            <span class="n">bd_test_dataset</span><span class="p">,</span>
            <span class="n">test_img_transform</span><span class="p">,</span>
            <span class="n">test_label_transform</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">stage1_results</span> <span class="o">=</span> <span class="n">clean_train_dataset_with_transform</span><span class="p">,</span> \
                              <span class="n">clean_test_dataset_with_transform</span><span class="p">,</span> \
                              <span class="n">bd_train_dataset_with_transform</span><span class="p">,</span> \
                              <span class="n">bd_test_dataset_with_transform</span></div>

    <span class="k">def</span> <span class="nf">stage2_training</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;stage2 start&quot;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="s1">&#39;args&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span>
        <span class="n">args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span>

        <span class="n">clean_train_dataset_with_transform</span><span class="p">,</span> \
        <span class="n">clean_test_dataset_with_transform</span><span class="p">,</span> \
        <span class="n">bd_train_dataset_with_transform</span><span class="p">,</span> \
        <span class="n">bd_test_dataset_with_transform</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage1_results</span>

        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;cuda:</span><span class="si">{</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">[</span><span class="mi">5</span><span class="p">:]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="s2">&quot;,&quot;</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">device</span> <span class="k">else</span> <span class="n">args</span><span class="o">.</span><span class="n">device</span>
                <span class="c1"># since DataParallel only allow .to(&quot;cuda&quot;)</span>
            <span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
        <span class="p">)</span>

<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        start real source code part</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;test_batch_size&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
            <span class="s2">&quot;log_interval&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
            <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s2">&quot;loss_threshold&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">backdoor_batch_loss_threshold</span><span class="p">,</span>
            <span class="s2">&quot;poisoning_proportion&quot;</span><span class="p">:</span> <span class="mf">1.1</span><span class="p">,</span>  <span class="c1"># not useful in common poison, just set &gt; 1</span>
            <span class="s2">&quot;backdoor_label&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">attack_target</span><span class="p">,</span>
            <span class="s2">&quot;backdoor&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">&quot;loss_balance&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">weight_loss_balance_mode</span><span class="p">,</span>  <span class="c1"># MGDA or fixed</span>
            <span class="s2">&quot;mgda_normalize&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">mgda_normalize</span><span class="p">,</span>
            <span class="s2">&quot;fixed_scales&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;backdoor&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">fix_scale_backdoor_weight</span><span class="p">,</span>
                <span class="s2">&quot;normal&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">fix_scale_normal_weight</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s2">&quot;loss_tasks&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;backdoor&quot;</span><span class="p">,</span> <span class="s2">&quot;normal&quot;</span><span class="p">],</span>
        <span class="p">}</span>
        <span class="n">args</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="n">helper</span> <span class="o">=</span> <span class="n">Helper</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">create_table</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">))</span>

        <span class="n">criterion</span> <span class="o">=</span> <span class="n">argparser_criterion</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

        <span class="n">run</span><span class="p">(</span>
            <span class="n">helper</span><span class="p">,</span>
            <span class="n">clean_test_dataloader</span><span class="o">=</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">clean_test_dataset_with_transform</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                             <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                             <span class="n">pin_memory</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span> <span class="p">),</span>
            <span class="n">bd_test_dataloader</span><span class="o">=</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">bd_test_dataset_with_transform</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                          <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                          <span class="n">pin_memory</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span> <span class="p">),</span>
            <span class="n">criterion</span><span class="o">=</span><span class="n">criterion</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
        <span class="p">)</span>

<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        end real source code part</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="n">save_attack_result</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="n">helper</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="n">data_path</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dataset_path</span><span class="p">,</span>
            <span class="n">img_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">img_size</span><span class="p">,</span>
            <span class="n">clean_data</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">bd_train</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">bd_test</span><span class="o">=</span><span class="n">bd_test_dataset_with_transform</span><span class="p">,</span>
            <span class="n">save_path</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span>
        <span class="p">)</span></div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">attack</span> <span class="o">=</span> <span class="n">Blind</span><span class="p">()</span>
    <span class="n">attack</span><span class="o">.</span><span class="n">attack</span><span class="p">()</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">MIT License</span>

<span class="sd">Copyright (c) [year] [fullname]</span>

<span class="sd">Permission is hereby granted, free of charge, to any person obtaining a copy</span>
<span class="sd">of this software and associated documentation files (the &quot;Software&quot;), to deal</span>
<span class="sd">in the Software without restriction, including without limitation the rights</span>
<span class="sd">to use, copy, modify, merge, publish, distribute, sublicense, and/or sell</span>
<span class="sd">copies of the Software, and to permit persons to whom the Software is</span>
<span class="sd">furnished to do so, subject to the following conditions:</span>

<span class="sd">The above copyright notice and this permission notice shall be included in all</span>
<span class="sd">copies or substantial portions of the Software.</span>

<span class="sd">THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span>
<span class="sd">IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span>
<span class="sd">FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE</span>
<span class="sd">AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span>
<span class="sd">LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</span>
<span class="sd">OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE</span>
<span class="sd">SOFTWARE.</span>
<span class="sd">&#39;&#39;&#39;</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, SCLBD.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>